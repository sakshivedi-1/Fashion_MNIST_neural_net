# Fashion-MNIST Neural Network Implementation

This repository contains a flexible, NumPy-based implementation of a Feedforward Neural Network built from scratch for the Fashion-MNIST classification task. This project was completed as part of the Atri Assignment to demonstrate understanding of Backpropagation, Gradient Descent variants, and hyperparameter tuning using Weights & Biases (Wandb).

## üìå Project Overview
The goal of this project is to classify images from the **Fashion-MNIST** dataset into 10 categories (e.g., T-shirt, Trouser, Bag) without using high-level frameworks like Keras/PyTorch for the model architecture.

### Key Features:
* **Built from Scratch:** No automatic differentiation or pre-built layers. All forward and backward passes are implemented using `numpy`.
* **Flexible Architecture:** Supports variable number of hidden layers and neuron counts.
* **Multiple Optimizers:** Implementation of 6 optimizers:
    * SGD
    * Momentum
    * Nesterov Accelerated Gradient (NAG)
    * RMSprop
    * Adam
    * Nadam
* **Experiment Tracking:** Integrated with **Wandb** for hyperparameter sweeps and visualization.
* **Activation Functions:** Support for ReLU, Sigmoid, and Tanh.

## üöÄ Getting Started

### Prerequisites
You need Python 3.x and the following libraries:
* `numpy`
* `pandas`
* `matplotlib`
* `wandb` (for experiment tracking)
* `scikit-learn` (for confusion matrix)
* `keras` (only for downloading the dataset)

### Installation
1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/your-username/your-repo-name.git](https://github.com/your-username/your-repo-name.git)
    cd your-repo-name
    ```

2.  **Install dependencies:**
    ```bash
    pip install numpy pandas matplotlib wandb scikit-learn tensorflow
    ```

## üèÉ‚Äç‚ôÇÔ∏è How to Run

### Method 1: Google Colab (Recommended)
1.  Open the file `Atri_Assignment_FashionMNIST.ipynb` in Google Colab.
2.  **Enable GPU:** Go to `Runtime` > `Change runtime type` > Select `T4 GPU`.
3.  **Run Cells:** Execute the cells sequentially.
    * *Note:* You will be prompted to log in to your Wandb account in the first few cells. Copy your API key from [wandb.ai/authorize](https://wandb.ai/authorize) when asked.

### Method 2: Local Machine
1.  Ensure you have Jupyter Notebook installed.
2.  Launch the notebook:
    bash
    jupyter notebook Atri_Assignment_FashionMNIST.ipynb
  
3.  Run all cells.

## ‚öôÔ∏è Usage & Configuration

### Training the Model
To train the model with specific hyperparameters, you can modify the `train()` function call or use the Wandb sweep configuration dictionary in the notebook.

**Example Configuration:**
python
config = {
    'epochs': 10,
    'batch_size': 32,
    'hidden_layers': 3,
    'hidden_size': 64,
    'learning_rate': 1e-3,
    'optimizer': 'nadam',
    'activation': 'relu',
    'weight_init': 'xavier',
    'weight_decay': 0.0005
}
Running Sweeps (Hyperparameter Tuning)
The notebook includes a sweep_config dictionary. To start a new sweep:

Define your parameter ranges in sweep_config (Question 4).

Run the wandb.sweep command provided in the notebook.

Use the generated sweep_id to start the agent: wandb.agent(sweep_id, train).

üìä Results & Analysis
The project analyzes the performance of different configurations using Parallel Coordinates plots and Correlation matrices generated by Wandb.

Best Optimizer: (Update this after your run, e.g., Nadam)

Best Activation: (Update this, e.g., ReLU)

Evaluation: The final model is evaluated on the test set, and a confusion matrix is plotted to visualize class-wise performance.

üìù Assignment Requirements Checklist
[x] Question 1: Fashion-MNIST Data Visualization

[x] Question 2: Flexible Feedforward Neural Network Class

[x] Question 3: Backpropagation with 6 Optimizers

[x] Question 4: Wandb Hyperparameter Sweep

[x] Question 5: Accuracy Plots

[x] Question 6: Observations & Inferences

[x] Question 7: Confusion Matrix on Test Set

[x] Question 8: Squared Error vs. Cross Entropy Loss Comparison

[x] Question 10: MNIST Recommendations

